{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285345a6-a69c-4ce0-a0b1-d398c8d00f7a",
   "metadata": {},
   "source": [
    "# Loss functions\n",
    "\n",
    "**Goal:** Build up some intuition for the Hungarian loss, and how to build it in python :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17954f44-86a2-453f-bef7-83c36743664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from absl import logging\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# The slot attn code\n",
    "import os\n",
    "os.sys.path.append('../google-research')\n",
    "\n",
    "import slot_attention.data as data_utils\n",
    "import slot_attention.model as model_utils\n",
    "import slot_attention.utils as utils\n",
    "\n",
    "from slot_attention.set_prediction.train import train_step\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3042caeb-7c5b-40ba-aade-943b4ef3ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_slots = 3\n",
    "nPhotons = 2\n",
    "nFeatures = 3 # (x,y,E)\n",
    "\n",
    "y_pred = tf.random.normal((batch_size, num_slots, nFeatures))\n",
    "y_true = tf.random.normal((batch_size, nPhotons,  nFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7c6d13-16c3-4a0e-a9ed-39dbbcb4a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hungarian_weighted_MSE_loss(x, y):\n",
    "    \"\"\"Huber loss for sets, matching elements with the Hungarian algorithm.\n",
    "\n",
    "    This loss is used as reconstruction loss in the paper 'Deep Set Prediction\n",
    "    Networks' https://arxiv.org/abs/1906.06565, see Eq. 2. For each element in the\n",
    "    batches we wish to compute min_{pi} ||y_i - x_{pi(i)}||^2 where pi is a\n",
    "    permutation of the set elements. We first compute the pairwise distances\n",
    "    between each point in both sets and then match the elements using the scipy\n",
    "    implementation of the Hungarian algorithm. This is applied for every set in\n",
    "    the two batches. Note that if the number of points does not match, some of the\n",
    "    elements will not be matched. As distance function we use the Huber loss.\n",
    "\n",
    "    Args:\n",
    "    x: Batch of sets of size [batch_size, n_points, dim_points]. Each set in the\n",
    "      batch contains n_points many points, each represented as a vector of\n",
    "      dimension dim_points.\n",
    "    y: Batch of sets of size [batch_size, n_points, dim_points].\n",
    "\n",
    "    Returns:\n",
    "    Average distance between all sets in the two batches.\n",
    "    \"\"\"\n",
    "    pairwise_cost = tf.losses.Huber(reduction=tf.keras.losses.Reduction.NONE)(\n",
    "      tf.expand_dims(y, axis=-2), tf.expand_dims(x, axis=-3))\n",
    "    indices = np.array(\n",
    "      list(map(scipy.optimize.linear_sum_assignment, pairwise_cost)))\n",
    "\n",
    "    transposed_indices = np.transpose(indices, axes=(0, 2, 1))\n",
    "\n",
    "    actual_costs = tf.gather_nd(\n",
    "      pairwise_cost, transposed_indices, batch_dims=1)\n",
    "\n",
    "    return tf.reduce_mean(tf.reduce_sum(actual_costs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9513d5c-d322-49a9-b0ee-c14823a52d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512, 2, 1, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(y_true, axis=-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d43b9d-e472-44eb-bb5e-4ac66cd423a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512, 1, 3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(y_pred, axis=-3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f5c824-6194-49fe-a170-0975f29c9313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = (tf.expand_dims(y_true, axis=-2) - tf.expand_dims(y_pred, axis=-3))**2\n",
    "\n",
    "# Sum over the final features\n",
    "MSE_manual = tf.math.reduce_mean(mse,axis=-1)\n",
    "MSE_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c4999e-f371-4112-87a5-249e377eb5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512, 2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_tf = tf.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)(\n",
    "    tf.expand_dims(y_true, axis=-2), tf.expand_dims(y_pred, axis=-3))\n",
    "MSE_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff547124-9c46-49f9-bc7a-4b0cb183ec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.9073486e-06>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(MSE_manual - MSE_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346bed1-a440-4dbe-8c0d-c4efc1123c71",
   "metadata": {},
   "source": [
    "OK, I understand what this function is doing (up to floating point errors!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3df52254-3092-4c07-9137-4ed73d15c0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Huber_tf = tf.losses.Huber(reduction=tf.keras.losses.Reduction.NONE)(\n",
    "    tf.expand_dims(y_true, axis=-2), tf.expand_dims(y_pred, axis=-3))\n",
    "Huber_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67f79338-4cd1-4bc3-89b3-af85232739b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.losses.Huber"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c31c0b-fb0d-475a-bc6f-8f5f1945aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8617048f-b0a7-4ba3-a0a4-11a4aab25c6f",
   "metadata": {},
   "source": [
    "`linear_sum_assignment` solves the problem of minimizing a cost matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed250b33-cbfc-438b-aa9c-218c07599c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mlinear_sum_assignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Solve the linear sum assignment problem.\n",
       "\n",
       "The linear sum assignment problem is also known as minimum weight matching\n",
       "in bipartite graphs. A problem instance is described by a matrix C, where\n",
       "each C[i,j] is the cost of matching vertex i of the first partite set\n",
       "(a \"worker\") and vertex j of the second set (a \"job\"). The goal is to find\n",
       "a complete assignment of workers to jobs of minimal cost.\n",
       "\n",
       "Formally, let X be a boolean matrix where :math:`X[i,j] = 1` iff row i is\n",
       "assigned to column j. Then the optimal assignment has cost\n",
       "\n",
       ".. math::\n",
       "    \\min \\sum_i \\sum_j C_{i,j} X_{i,j}\n",
       "\n",
       "where, in the case where the matrix X is square, each row is assigned to\n",
       "exactly one column, and each column to exactly one row.\n",
       "\n",
       "This function can also solve a generalization of the classic assignment\n",
       "problem where the cost matrix is rectangular. If it has more rows than\n",
       "columns, then not every row needs to be assigned to a column, and vice\n",
       "versa.\n",
       "\n",
       "The problem is also solved for sparse inputs in\n",
       ":func:`scipy.sparse.csgraph.min_weight_full_bipartite_matching` which\n",
       "may perform better if the input is sparse, or for certain classes of\n",
       "problems, such as uniformly distributed costs.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "cost_matrix : array\n",
       "    The cost matrix of the bipartite graph.\n",
       "\n",
       "maximize : bool (default: False)\n",
       "    Calculates a maximum weight matching if true.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "row_ind, col_ind : array\n",
       "    An array of row indices and one of corresponding column indices giving\n",
       "    the optimal assignment. The cost of the assignment can be computed\n",
       "    as ``cost_matrix[row_ind, col_ind].sum()``. The row indices will be\n",
       "    sorted; in the case of a square cost matrix they will be equal to\n",
       "    ``numpy.arange(cost_matrix.shape[0])``.\n",
       "\n",
       "Notes\n",
       "-----\n",
       ".. versionadded:: 0.17.0\n",
       "\n",
       "References\n",
       "----------\n",
       "\n",
       "1. https://en.wikipedia.org/wiki/Assignment_problem\n",
       "\n",
       "2. DF Crouse. On implementing 2D rectangular assignment algorithms.\n",
       "   *IEEE Transactions on Aerospace and Electronic Systems*,\n",
       "   52(4):1679-1696, August 2016, :doi:`10.1109/TAES.2016.140952`\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> cost = np.array([[4, 1, 3], [2, 0, 5], [3, 2, 2]])\n",
       ">>> from scipy.optimize import linear_sum_assignment\n",
       ">>> row_ind, col_ind = linear_sum_assignment(cost)\n",
       ">>> col_ind\n",
       "array([1, 0, 2])\n",
       ">>> cost[row_ind, col_ind].sum()\n",
       "5\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.8/site-packages/scipy/optimize/_lsap.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03355431-7829-4af8-b63d-e2c91739fbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mlinear_sum_assignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Solve the linear sum assignment problem.\n",
       "\n",
       "The linear sum assignment problem is also known as minimum weight matching\n",
       "in bipartite graphs. A problem instance is described by a matrix C, where\n",
       "each C[i,j] is the cost of matching vertex i of the first partite set\n",
       "(a \"worker\") and vertex j of the second set (a \"job\"). The goal is to find\n",
       "a complete assignment of workers to jobs of minimal cost.\n",
       "\n",
       "Formally, let X be a boolean matrix where :math:`X[i,j] = 1` iff row i is\n",
       "assigned to column j. Then the optimal assignment has cost\n",
       "\n",
       ".. math::\n",
       "    \\min \\sum_i \\sum_j C_{i,j} X_{i,j}\n",
       "\n",
       "where, in the case where the matrix X is square, each row is assigned to\n",
       "exactly one column, and each column to exactly one row.\n",
       "\n",
       "This function can also solve a generalization of the classic assignment\n",
       "problem where the cost matrix is rectangular. If it has more rows than\n",
       "columns, then not every row needs to be assigned to a column, and vice\n",
       "versa.\n",
       "\n",
       "The problem is also solved for sparse inputs in\n",
       ":func:`scipy.sparse.csgraph.min_weight_full_bipartite_matching` which\n",
       "may perform better if the input is sparse, or for certain classes of\n",
       "problems, such as uniformly distributed costs.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "cost_matrix : array\n",
       "    The cost matrix of the bipartite graph.\n",
       "\n",
       "maximize : bool (default: False)\n",
       "    Calculates a maximum weight matching if true.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "row_ind, col_ind : array\n",
       "    An array of row indices and one of corresponding column indices giving\n",
       "    the optimal assignment. The cost of the assignment can be computed\n",
       "    as ``cost_matrix[row_ind, col_ind].sum()``. The row indices will be\n",
       "    sorted; in the case of a square cost matrix they will be equal to\n",
       "    ``numpy.arange(cost_matrix.shape[0])``.\n",
       "\n",
       "Notes\n",
       "-----\n",
       ".. versionadded:: 0.17.0\n",
       "\n",
       "References\n",
       "----------\n",
       "\n",
       "1. https://en.wikipedia.org/wiki/Assignment_problem\n",
       "\n",
       "2. DF Crouse. On implementing 2D rectangular assignment algorithms.\n",
       "   *IEEE Transactions on Aerospace and Electronic Systems*,\n",
       "   52(4):1679-1696, August 2016, :doi:`10.1109/TAES.2016.140952`\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> cost = np.array([[4, 1, 3], [2, 0, 5], [3, 2, 2]])\n",
       ">>> from scipy.optimize import linear_sum_assignment\n",
       ">>> row_ind, col_ind = linear_sum_assignment(cost)\n",
       ">>> col_ind\n",
       "array([1, 0, 2])\n",
       ">>> cost[row_ind, col_ind].sum()\n",
       "5\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.8/site-packages/scipy/optimize/_lsap.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d261abf4-8772-4330-a542-490bbf1daf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([0, 2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_rows, idx_cols = linear_sum_assignment(MSE_tf[0])\n",
    "idx_rows, idx_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa7129-1caf-485d-b83d-f4a17df56970",
   "metadata": {},
   "source": [
    "**Output:** Array of row indices and column indices corresponding to the optimal assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5837f940-0a7f-4c4a-93a3-b7b60b1eb0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.08726764, 2.491103  , 1.1471361 ],\n",
       "       [0.87472844, 1.4417597 , 1.3980832 ]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_tf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d685cc-5129-42a3-bcb9-58ae45df0c71",
   "metadata": {},
   "source": [
    "OK, based on looking at this, I think was `linear_sum_assignment` returns the row and column indices for the adjacency matrix that solves this bipartite graph matching problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8ab2c80-5dd8-4563-8db5-33789ea0291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let X be shape (2,3) be the adjacency matrix\n",
    "X = np.zeros_like(MSE_tf[0])\n",
    "X[idx_rows, idx_cols] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630ba31-9f97-4daf-b2b6-599852a7d18e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbc06f9c-e057-479b-8aef-a4ffab0b1b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3376bc7-b479-4fd2-939b-8947123bc27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4853508"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X * MSE_tf[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "702b03e5-0768-453d-91e0-7383636cca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array( list(map(linear_sum_assignment, MSE_tf)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18245c5a-2b84-4c0b-bdac-9525c2f6cb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 2, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d77d2b4-e31a-43c8-bf1d-f80ce5d9c861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389a7c2-0452-4d7e-8428-08057ddb9609",
   "metadata": {},
   "source": [
    "(I think) the output becomes a bit more transparent when we take the transpose (which is in fact what they're doing in the loss function calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cabeb05-9a7e-4792-bade-317dbb62ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_indices = np.transpose(indices, axes=(0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb921692-4e88-4411-8ba9-75a6d60e25d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed_indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172d76d-4551-42ba-8158-8a5d61466971",
   "metadata": {},
   "source": [
    "**What does this mean?**\n",
    "- Worker (truth particle) 0 matches to job (slot) 0\n",
    "- Worker (truth particle) 1 matches to job (slot) 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce668018-6359-4586-b70c-f94495a1e50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
       "\n",
       "`indices` is an K-dimensional integer tensor, best thought of as a\n",
       "(K-1)-dimensional tensor of indices into `params`, where each element defines\n",
       "a slice of `params`:\n",
       "\n",
       "    output[\\\\(i_0, ..., i_{K-2}\\\\)] = params[indices[\\\\(i_0, ..., i_{K-2}\\\\)]]\n",
       "\n",
       "Whereas in `tf.gather` `indices` defines slices into the first\n",
       "dimension of `params`, in `tf.gather_nd`, `indices` defines slices into the\n",
       "first `N` dimensions of `params`, where `N = indices.shape[-1]`.\n",
       "\n",
       "The last dimension of `indices` can be at most the rank of\n",
       "`params`:\n",
       "\n",
       "    indices.shape[-1] <= params.rank\n",
       "\n",
       "The last dimension of `indices` corresponds to elements\n",
       "(if `indices.shape[-1] == params.rank`) or slices\n",
       "(if `indices.shape[-1] < params.rank`) along dimension `indices.shape[-1]`\n",
       "of `params`.  The output tensor has shape\n",
       "\n",
       "    indices.shape[:-1] + params.shape[indices.shape[-1]:]\n",
       "\n",
       "Additionally both 'params' and 'indices' can have M leading batch\n",
       "dimensions that exactly match. In this case 'batch_dims' must be M.\n",
       "\n",
       "Note that on CPU, if an out of bound index is found, an error is returned.\n",
       "On GPU, if an out of bound index is found, a 0 is stored in the\n",
       "corresponding output value.\n",
       "\n",
       "Some examples below.\n",
       "\n",
       "Simple indexing into a matrix:\n",
       "\n",
       "```python\n",
       "    indices = [[0, 0], [1, 1]]\n",
       "    params = [['a', 'b'], ['c', 'd']]\n",
       "    output = ['a', 'd']\n",
       "```\n",
       "\n",
       "Slice indexing into a matrix:\n",
       "\n",
       "```python\n",
       "    indices = [[1], [0]]\n",
       "    params = [['a', 'b'], ['c', 'd']]\n",
       "    output = [['c', 'd'], ['a', 'b']]\n",
       "```\n",
       "\n",
       "Indexing into a 3-tensor:\n",
       "\n",
       "```python\n",
       "    indices = [[1]]\n",
       "    params = [[['a0', 'b0'], ['c0', 'd0']],\n",
       "              [['a1', 'b1'], ['c1', 'd1']]]\n",
       "    output = [[['a1', 'b1'], ['c1', 'd1']]]\n",
       "\n",
       "\n",
       "    indices = [[0, 1], [1, 0]]\n",
       "    params = [[['a0', 'b0'], ['c0', 'd0']],\n",
       "              [['a1', 'b1'], ['c1', 'd1']]]\n",
       "    output = [['c0', 'd0'], ['a1', 'b1']]\n",
       "\n",
       "\n",
       "    indices = [[0, 0, 1], [1, 0, 1]]\n",
       "    params = [[['a0', 'b0'], ['c0', 'd0']],\n",
       "              [['a1', 'b1'], ['c1', 'd1']]]\n",
       "    output = ['b0', 'b1']\n",
       "```\n",
       "\n",
       "The examples below are for the case when only indices have leading extra\n",
       "dimensions. If both 'params' and 'indices' have leading batch dimensions, use\n",
       "the 'batch_dims' parameter to run gather_nd in batch mode.\n",
       "\n",
       "Batched indexing into a matrix:\n",
       "\n",
       "```python\n",
       "    indices = [[[0, 0]], [[0, 1]]]\n",
       "    params = [['a', 'b'], ['c', 'd']]\n",
       "    output = [['a'], ['b']]\n",
       "```\n",
       "\n",
       "Batched slice indexing into a matrix:\n",
       "\n",
       "```python\n",
       "    indices = [[[1]], [[0]]]\n",
       "    params = [['a', 'b'], ['c', 'd']]\n",
       "    output = [[['c', 'd']], [['a', 'b']]]\n",
       "```\n",
       "\n",
       "Batched indexing into a 3-tensor:\n",
       "\n",
       "```python\n",
       "    indices = [[[1]], [[0]]]\n",
       "    params = [[['a0', 'b0'], ['c0', 'd0']],\n",
       "              [['a1', 'b1'], ['c1', 'd1']]]\n",
       "    output = [[[['a1', 'b1'], ['c1', 'd1']]],\n",
       "              [[['a0', 'b0'], ['c0', 'd0']]]]\n",
       "\n",
       "    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]]\n",
       "    params = [[['a0', 'b0'], ['c0', 'd0']],\n",
       "              [['a1', 'b1'], ['c1', 'd1']]]\n",
       "    output = [[['c0', 'd0'], ['a1', 'b1']],\n",
       "              [['a0', 'b0'], ['c1', 'd1']]]\n",
       "\n",
       "\n",
       "    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]]\n",
       "    params = [[['a0', 'b0'], ['c0', 'd0']],\n",
       "              [['a1', 'b1'], ['c1', 'd1']]]\n",
       "    output = [['b0', 'b1'], ['d0', 'c1']]\n",
       "```\n",
       "\n",
       "Examples with batched 'params' and 'indices':\n",
       "\n",
       "```python\n",
       "    batch_dims = 1\n",
       "    indices = [[1], [0]]\n",
       "    params = [[['a0', 'b0'], ['c0', 'd0']],\n",
       "              [['a1', 'b1'], ['c1', 'd1']]]\n",
       "    output = [['c0', 'd0'], ['a1', 'b1']]\n",
       "\n",
       "    batch_dims = 1\n",
       "    indices = [[[1]], [[0]]]\n",
       "    params = [[['a0', 'b0'], ['c0', 'd0']],\n",
       "              [['a1', 'b1'], ['c1', 'd1']]]\n",
       "    output = [[['c0', 'd0']], [['a1', 'b1']]]\n",
       "\n",
       "    batch_dims = 1\n",
       "    indices = [[[1, 0]], [[0, 1]]]\n",
       "    params = [[['a0', 'b0'], ['c0', 'd0']],\n",
       "              [['a1', 'b1'], ['c1', 'd1']]]\n",
       "    output = [['c0'], ['b1']]\n",
       "```\n",
       "\n",
       "See also `tf.gather`.\n",
       "\n",
       "Args:\n",
       "  params: A `Tensor`. The tensor from which to gather values.\n",
       "  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
       "    Index tensor.\n",
       "  name: A name for the operation (optional).\n",
       "  batch_dims: An integer or a scalar 'Tensor'. The number of batch dimensions.\n",
       "\n",
       "Returns:\n",
       "  A `Tensor`. Has the same type as `params`.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/envs/rapids/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?tf.gather_nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb796e-9957-4ce0-810d-e760c682ef4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
