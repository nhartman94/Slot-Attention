{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e8954f-ff8d-4d0c-b63c-c2d276bb1f4e",
   "metadata": {},
   "source": [
    "# ISA and combined loss - evaluating different $\\alpha$\n",
    "\n",
    "We've defined a new loss that is \n",
    "\n",
    "$\\mathcal{L}_{tot} = \\mathcal{L}_{BCE} + \\alpha \\cdot \\mathcal{L}_{MSE}$ \n",
    "\n",
    "where BCE stands for binary cross entropy and MSE for mean squared error. $\\alpha$ is for scaling. The BCE is supposed to separate features from a single picture into one picture each (e.g. each ring in a separate picture) while the MSE computes the properties of each feature (e.g. $x$, $y$ and $R$ of each ring). In this ring example $x$ and $y$ are computed with respect to the center-of-mass (regarding the hits) of each single-ring picture.\n",
    "\n",
    "The goal of this notebook is \n",
    "1. to load the models for $\\alpha = 1, 2$ at a lower epoch number (as we see unlearning for higher epochs, see Nicoles losses) and plot some example pictures. \n",
    "2. Think of a good metrix to evaluate the separation of the rings.\n",
    "\n",
    "Let's get started!! :-) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36425f48-adce-47dd-9819-f38a5e9b641e",
   "metadata": {},
   "source": [
    "### Import, load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a948adef-a908-4b57-9c97-8caada0ae9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlp\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import json, yaml, os\n",
    "os.sys.path.append('./../../code')\n",
    "\n",
    "from plotting import plot_kslots, plot_kslots_iters\n",
    "from data import make_batch\n",
    "from model import InvariantSlotAttention\n",
    "\n",
    "# Set numpy seed for test set sampling \n",
    "np.random.seed(24082023)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24044d5-0502-4f49-a181-e37257d50e48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09d3847-7595-47fe-9016-12417938f215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071454ac-0a7b-4d8d-97c8-d28b4c4260c8",
   "metadata": {},
   "source": [
    "Load configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48771fe-247e-4bc4-ba33-d063e2ef287c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cID_prev = 'isa-alpha1'\n",
    "with open(f'./../../code/configs/{cID_prev}.yaml') as f:\n",
    "    cd = yaml.safe_load(f)\n",
    "\n",
    "hps = cd['hps']\n",
    "hps['device'] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad3f906a-eec6-4500-a98b-8a7073942b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch_seed = 29082023\n",
    "torch.manual_seed( torch_seed )\n",
    "\n",
    "import random\n",
    "random.seed(torch_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1684bc-2ea0-45f3-b737-002144d648af",
   "metadata": {},
   "source": [
    "Load model and its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a53615-08d1-4363-bee3-a9f856e60dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = InvariantSlotAttention(**hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980ad8c2-4cde-4334-98c6-2ba446c2e060",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from an earlier training 11194\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './../../code/models/isa-alpha1/m_11194.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m weightPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./../../code/models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcID_prev\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlastIter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting from an earlier training\u001b[39m\u001b[38;5;124m'\u001b[39m,lastIter)\n\u001b[0;32m----> 5\u001b[0m m\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweightPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/raven/u/saumi/nn-venv/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/raven/u/saumi/nn-venv/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/raven/u/saumi/nn-venv/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './../../code/models/isa-alpha1/m_11194.pt'"
     ]
    }
   ],
   "source": [
    "lastIter = 11000\n",
    "weightPath = f'./../../code/models/{cID_prev}/m_{lastIter}.pt'\n",
    "print(f'Starting from an earlier training',lastIter)\n",
    "\n",
    "m.load_state_dict(torch.load(weightPath,map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7891af0-d8ba-4ad0-acac-5c5bf4903077",
   "metadata": {},
   "source": [
    "Load/generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f7a16-aa31-4f38-964e-9cfdce97c290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 100\n",
    "kwargs = cd['data']\n",
    "\n",
    "X, Y, mask = make_batch(N_events=bs, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe291ae-641c-46bf-ad4d-cd33515aa0e9",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5aedca-f57a-4351-8eed-7e3d52f54891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from train import hungarian_matching\n",
    "import torch.nn.functional as F\n",
    "\n",
    "k_slots=3\n",
    "max_n_rings=2\n",
    "resolution=(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14558a1a-c789-483f-9ec9-edfcf8491220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = cd['opt']['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b9034-ec4d-4fef-9b4c-ad00f44ec879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    torch.manual_seed(torch_seed)\n",
    "    queries, att, Y_pred = m(X)\n",
    "         \n",
    "    # Reshape the target mask to be flat in the pixels (same shape as att)\n",
    "    flat_mask = mask.reshape(-1,max_n_rings, np.prod(resolution))      \n",
    "\n",
    "    att_ext  = torch.tile(att.unsqueeze(2), dims=(1,1,max_n_rings,1)) \n",
    "    mask_ext = torch.tile(flat_mask.unsqueeze(1),dims=(1,k_slots,1,1)) \n",
    "\n",
    "    pairwise_cost = F.binary_cross_entropy(att_ext,mask_ext,reduction='none').mean(axis=-1)\n",
    "\n",
    "    # pairwise_cost = comb_loss(att,flat_mask,Y,Y_pred,alpha)\n",
    "    indices = hungarian_matching(pairwise_cost)\n",
    "\n",
    "    # Apply the sorting to the predict\n",
    "    bis=torch.arange(bs).to(device)\n",
    "    indices=indices.to(device)\n",
    "\n",
    "    # Loss calc\n",
    "    slots_sorted = torch.cat([att[bis,indices[:,0,ri]].unsqueeze(1) for ri in range(max_n_rings)],dim=1)\n",
    "    rings_sorted = torch.cat([flat_mask[bis,indices[:,1,ri]].unsqueeze(1) for ri in range(max_n_rings)],dim=1)\n",
    "    l_bce = F.binary_cross_entropy(slots_sorted,rings_sorted,reduction='none').sum(axis=1).mean(axis=-1)\n",
    "\n",
    "    Y_pred_sorted = torch.cat([Y_pred[bis,indices[:,0,ri]].unsqueeze(1) for ri in range(max_n_rings)],dim=1)\n",
    "    Y_true_sorted = torch.cat([Y[bis,indices[:,1,ri]].unsqueeze(1) for ri in range(max_n_rings)],dim=1)\n",
    "\n",
    "    l_mse = torch.nn.MSELoss(reduction='none')(Y_pred_sorted,Y_true_sorted).sum(axis=1).mean(axis=-1)\n",
    "\n",
    "    # Calculate the loss\n",
    "    print(l_bce.shape)\n",
    "    print(l_mse.shape)\n",
    "    li = l_bce + alpha*l_mse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89cee39-6a1e-4f01-8c93-8f72609df451",
   "metadata": {},
   "source": [
    "Now let's histogram the loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057795c-3132-4d80-85f7-bbcf6aeb308f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(li.numpy(),100,color='C1', label=\"$L_{tot}$\", range=(0, 0.35))\n",
    "plt.hist(l_bce.numpy(),100,color='r', label=\"$L_{BCE}$\", alpha=0.55, range=(0, 0.35))\n",
    "plt.hist(l_mse.numpy(),100,color='green', label=\"$L_{MSE}$\", alpha=0.55, range=(0, 0.35))\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Entries')\n",
    "\n",
    "ylim = plt.ylim()\n",
    "plt.plot([.01]*2,ylim,'k--')\n",
    "plt.plot([.03]*2,ylim,'grey',ls='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ce6d4b-2625-4f20-be09-8138eabb1298",
   "metadata": {},
   "source": [
    "### Looking at examples\n",
    "\n",
    "Let's plot some example rings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0960db0-1466-4806-9907-e65939cd4d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_chosen_slots(losses, mask, att_img, Y_true, Y_pred, color='C0',cmap='Blues',figname=''):\n",
    "    n_rings = att_img.shape[0]\n",
    "    fig, axs = plt.subplots(1,n_rings+2,figsize=(3*(n_rings + 2) ,2.5))\n",
    "\n",
    "    for k,v in losses.items():\n",
    "        axs[0].plot(v,label=k)\n",
    "    axs[0].set_xlabel('Iters')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "    \n",
    "    imgs   = [mask] + [att_img[i] for i in range(n_rings)]\n",
    "    titles = ['Target']+[f'Slot {i}' for i in range(n_rings)]\n",
    "    extent = [-0.5, 0.5]*2\n",
    "    for i, (ax,img,title) in enumerate(zip(axs[1:],imgs, titles)):\n",
    "        \n",
    "        im = ax.imshow(img.detach().cpu().numpy(),cmap=cmap,\n",
    "                       extent=extent,origin='lower') #,vmin=0,vmax=1)\n",
    "\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "        ax.set_title(title)\n",
    "        \n",
    "\n",
    "    # Add on the target image\n",
    "    axi = axs[1]\n",
    "    c_true = 'r'\n",
    "    c_pred = 'k'\n",
    "    for yi in Y_true.cpu().numpy():\n",
    "    \n",
    "        axi.scatter(*yi[:2],marker='x',color=c_true)\n",
    "        circle = Circle(yi[:2],yi[2],fill=False,color=c_true)\n",
    "        axi.add_patch(circle)\n",
    "        \n",
    "        axi.set_xlim(-0.5,0.5)\n",
    "        axi.set_ylim(-0.5,0.5)\n",
    "    \n",
    "    for axi,yi,oi in zip(axs[2:],Y_true.cpu().numpy(),Y_pred.detach().cpu().numpy()):\n",
    "        \n",
    "        axi.scatter(*yi[:2],marker='x',color=c_true)\n",
    "        circle = Circle(yi[:2],yi[2],fill=False,color=c_true)\n",
    "        axi.add_patch(circle)\n",
    "        \n",
    "        axi.scatter(*oi[:2],marker='x',color=c_pred)\n",
    "        circle = Circle(oi[:2],oi[2],fill=False,color=c_pred)\n",
    "        axi.add_patch(circle)\n",
    "\n",
    "        axi.set_xlim(-0.5,0.5)\n",
    "        axi.set_ylim(-0.5,0.5)\n",
    "        \n",
    "    #if figname:\n",
    "    #    plt.savefig(figname)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8250ef-a715-4baa-845e-efdb37d088f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(f'./../../code/models/{cID_prev}/loss.json')\n",
    "# returns JSON object as a dictionary\n",
    "losses = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e3caf-0a40-4bc4-8b3e-ee4095e4344d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iEvt = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08505d88-245d-425f-9654-63f0db0f1a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_chosen_slots(losses,\n",
    "                  mask[iEvt].sum(axis=0), \n",
    "                  slots_sorted[iEvt].reshape(max_n_rings,*resolution),\n",
    "                  Y_true_sorted[iEvt],\n",
    "                  Y_pred_sorted[iEvt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb6a1f2-9e7e-4baa-bba7-8e653c529cad",
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.imshow(mask[iEvt].sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3959f1-cb96-47d0-99a6-85ca26897f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " plt.imshow(mask[iEvt][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46318952-6c6c-408f-a18f-1e2a94b8a0db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(mask[iEvt][1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54377657-20c8-417f-95cc-42be7ee7c949",
   "metadata": {},
   "source": [
    "# Metrix: Use KL-divergence\n",
    "\n",
    "This is \n",
    "\n",
    "$KL(p,q) = \\sum_i p_i \\log{\\frac{p_i}{q_i}} = \\sum_i p_i \\log{p_i} - \\sum_i p_i \\log{q_i}$\n",
    "\n",
    "and is a extension of the BCE as mixed terms (if $p_i$ not binary) get subtracted too. This should be a metrix that works for rings and clusters. \n",
    "Check [this page](https://pytorch.org/docs/stable/generated/torch.nn.functional.kl_div.html) for the pytorch doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794efa3-8de0-4815-8c9d-4f7d7399f292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_kl = F.kl_div(torch.log(slots_sorted),rings_sorted,reduction='none').sum(axis=1).mean(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0a17c-a5a5-4afd-ad4f-20966f10270f",
   "metadata": {},
   "source": [
    "Sanity-check: does the KL-divergence look similar to BCE? Only ~10% difference is suspected due to overlapping rings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743225a6-5748-453c-9ec1-4f5895bf6daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(l_kl.numpy(),100,color='purple', label=\"$L_{KL}$\", range=(0, 0.10), alpha=0.55)\n",
    "#plt.hist(l_bce.numpy(),100,color='r', label=\"$L_{BCE}$\", alpha=0.55, range=(0, 0.35))\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Entries')\n",
    "\n",
    "ylim = plt.ylim()\n",
    "plt.plot([.001]*2,ylim,'k--')\n",
    "plt.plot([.01]*2,ylim,'grey',ls='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf41b1d-f8d4-4f00-a17a-c8fd57823622",
   "metadata": {},
   "source": [
    "Let's look at some examples for good and bad separation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d2223-fea6-4eef-8ecd-15b78f42641d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mi = l_kl < 0.001 # good events\n",
    "torch.sum(mi)\n",
    "mj = l_kl > 0.01 # bad events\n",
    "torch.sum(mj)\n",
    "\n",
    "good_imgs = mask[mi].sum(axis=1)\n",
    "bad_imgs  = mask[mj].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ba418-eaf5-49c1-a9be-635dc9a28e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd7471-1d1a-4b2c-8f3e-863c0b013f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Good exs\n",
    "nrows = 5\n",
    "ncols = 10\n",
    "\n",
    "fig, axes = plt.subplots(nrows,ncols,figsize=(ncols*2,nrows*2))\n",
    "\n",
    "for i, ax_i in enumerate(axes):\n",
    "\n",
    "    for j, ax in enumerate(ax_i):\n",
    "\n",
    "        k = i * ncols + j \n",
    "        ax.axis('off')\n",
    "        \n",
    "        if k >= len(good_imgs):\n",
    "            break\n",
    "        \n",
    "        im = ax.imshow(good_imgs[k].numpy(),cmap='GnBu')\n",
    "\n",
    "        \n",
    "        # ax.set_title(0,0,f'evt={k}',transform=ax_ij.transAxes) \n",
    "\n",
    "fig.suptitle('Good examples (loss < 0.001)',va='top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735a337-fa0d-45d3-b98b-ec8be86c252f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55cb23c-8cf7-4ae2-9d6a-6c62aac1c1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bad exs\n",
    "nrows = 5\n",
    "ncols = 6\n",
    "\n",
    "fig, axes = plt.subplots(nrows,ncols,figsize=(ncols*2,nrows*2))\n",
    "\n",
    "for i, ax_i in enumerate(axes):\n",
    "\n",
    "    for j, ax in enumerate(ax_i):\n",
    "\n",
    "        k = i * ncols + j \n",
    "        ax.axis('off')\n",
    "        \n",
    "        if k >= len(bad_imgs):\n",
    "            break\n",
    "        \n",
    "        im = ax.imshow(bad_imgs[k].numpy(),cmap='GnBu')\n",
    "\n",
    "        \n",
    "        # ax.set_title(0,0,f'evt={k}',transform=ax_ij.transAxes) \n",
    "\n",
    "fig.suptitle('Bad examples (loss > 0.01)',va='top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5aaad-e423-4035-9198-a8b5c504c465",
   "metadata": {},
   "source": [
    "## Let's have a closer look at these \"bad\" separated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec60b8b4-cfe2-47fb-bdae-a0c815885376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_chosen_slots_only(mask, att_img, Y_true, Y_pred, color='C0',cmap='Blues',figname=''):\n",
    "    n_rings = att_img.shape[0]\n",
    "    fig, axs = plt.subplots(1,n_rings+1,figsize=(3*(n_rings + 2) ,2.5))\n",
    "   \n",
    "    imgs   = [mask] + [att_img[i] for i in range(n_rings)]\n",
    "    titles = ['Target']+[f'Slot {i}' for i in range(n_rings)]\n",
    "    extent = [-0.5, 0.5]*2\n",
    "    for i, (ax,img,title) in enumerate(zip(axs[0:],imgs, titles)):\n",
    "        \n",
    "        im = ax.imshow(img.detach().cpu().numpy(),cmap=cmap,\n",
    "                       extent=extent,origin='lower') #,vmin=0,vmax=1)\n",
    "\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "        ax.set_title(title)\n",
    "        \n",
    "\n",
    "    # Add on the target image\n",
    "    axi = axs[0]\n",
    "    c_true = 'r'\n",
    "    c_pred = 'k'\n",
    "    for yi in Y_true.cpu().numpy():\n",
    "    \n",
    "        axi.scatter(*yi[:2],marker='x',color=c_true)\n",
    "        circle = Circle(yi[:2],yi[2],fill=False,color=c_true)\n",
    "        axi.add_patch(circle)\n",
    "        \n",
    "        axi.set_xlim(-0.5,0.5)\n",
    "        axi.set_ylim(-0.5,0.5)\n",
    "    \n",
    "    for axi,yi,oi in zip(axs[1:],Y_true.cpu().numpy(),Y_pred.detach().cpu().numpy()):\n",
    "        \n",
    "        axi.scatter(*yi[:2],marker='x',color=c_true)\n",
    "        circle = Circle(yi[:2],yi[2],fill=False,color=c_true)\n",
    "        axi.add_patch(circle)\n",
    "        \n",
    "        axi.scatter(*oi[:2],marker='x',color=c_pred)\n",
    "        circle = Circle(oi[:2],oi[2],fill=False,color=c_pred)\n",
    "        axi.add_patch(circle)\n",
    "\n",
    "        axi.set_xlim(-0.5,0.5)\n",
    "        axi.set_ylim(-0.5,0.5)\n",
    "        \n",
    "    #if figname:\n",
    "    #    plt.savefig(figname)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e857a-4bed-4518-b514-4d81f143a3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_chosen_slots_only(\n",
    "                  mask[iEvt].sum(axis=0), \n",
    "                  slots_sorted[iEvt].reshape(max_n_rings,*resolution),\n",
    "                  Y_true_sorted[iEvt],\n",
    "                  Y_pred_sorted[iEvt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0df8d2-e364-4328-96dc-30f668ec6c23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for count, k in enumerate(np.where(l_kl > 0.01)[0]):\n",
    "    iEvt = k\n",
    "    print(\"KL: \", l_kl[iEvt])\n",
    "    plot_chosen_slots_only(\n",
    "                  mask[iEvt].sum(axis=0), \n",
    "                  slots_sorted[iEvt].reshape(max_n_rings,*resolution),\n",
    "                  Y_true_sorted[iEvt],\n",
    "                  Y_pred_sorted[iEvt])\n",
    "    if count>15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce60d91-2f1f-4091-bc4a-bcf05d7e732a",
   "metadata": {},
   "source": [
    "Good examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c544cf-9937-4885-ade0-ace68c097fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for count, k in enumerate(np.where(l_kl < 0.001)[0]):\n",
    "    iEvt = k\n",
    "    print(\"KL: \", l_kl[iEvt])\n",
    "    plot_chosen_slots_only(\n",
    "                  mask[iEvt].sum(axis=0), \n",
    "                  slots_sorted[iEvt].reshape(max_n_rings,*resolution),\n",
    "                  Y_true_sorted[iEvt],\n",
    "                  Y_pred_sorted[iEvt])\n",
    "    if count>15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46757326-dd05-4ab6-a83e-e40a7ed456b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,5)\n",
    "for k,v in losses.items():\n",
    "    print(np.argmin(v))\n",
    "    print(\"now: \", v[5000])\n",
    "    print(\"best: \", v[11194])\n",
    "    plt.plot(v,label=k)\n",
    "    plt.xlabel('Iters')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b094a-edf4-4f19-952d-16e31046d3b5",
   "metadata": {},
   "source": [
    "Ok reload this notebook for model at epoch 11194!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6bcc05-9e78-46e5-9d9f-e9165a0543f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarasvenv",
   "language": "python",
   "name": "sarasvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
