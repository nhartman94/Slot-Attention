/raven/u/saumi/multi-object-detection/Slot-Attention/code
models//isa-scclevr-EncStudy-moreCNN already exists
figures//isa-scclevr-EncStudy-moreCNN already exists
Starting from an earlier training from configs/isa-cosine-decay.yaml
iter 250 , loss 0.42417628 , lr 1.4994217771805423e-05
iter 500 , loss 0.30022648 , lr 2.9953760005996917e-05
iter 750 , loss 0.23575076 , lr 4.484404028148584e-05
iter 1000 , loss 0.2073984 , lr 5.963065021785413e-05
iter 1250 , loss 0.1616924 , lr 7.427944801512113e-05
iter 1500 , loss 0.15002957 , lr 8.875664641789544e-05
iter 1750 , loss 0.1595299 , lr 0.00010302889991381646
iter 2000 , loss 0.13485734 , lr 0.00011706339097770922
iter 2250 , loss 0.14074074 , lr 0.00013082791517476767
iter 2500 , loss 0.11332098 , lr 0.0001442909649383465
iter 2750 , loss 0.084806256 , lr 0.00015742181184056923
iter 3000 , loss 0.11309047 , lr 0.00017019058717695308
iter 3250 , loss 0.098135695 , lr 0.00018256836068959774
iter 3500 , loss 0.1067671 , lr 0.00019452721725717964
iter 3750 , loss 0.09052607 , lr 0.00020604033138403634
iter 4000 , loss 0.08096568 , lr 0.0002170820393249937
iter 4250 , loss 0.07476519 , lr 0.00022762790868729492
iter 4500 , loss 0.0731928 , lr 0.0002376548053560042
iter 4750 , loss 0.08099303 , lr 0.00024714095759458514
iter 5000 , loss 0.06497731 , lr 0.00025606601717798207
iter 5250 , loss 0.069212034 , lr 0.0002518201118299413
iter 5500 , loss 0.06860659 , lr 0.00024741720724952754
iter 5750 , loss 0.05709782 , lr 0.00024286409239647507
iter 6000 , loss 0.06364929 , lr 0.00023816778784387094
iter 6250 , loss 0.061454322 , lr 0.00023333553495294033
iter 6500 , loss 0.054834045 , lr 0.0002283747847073923
iter 6750 , loss 0.05831182 , lr 0.00022329318622454325
iter 7000 , loss 0.0512062 , lr 0.00021809857496093199
iter 7250 , loss 0.044839952 , lr 0.0002127989606306142
iter 7500 , loss 0.049859837 , lr 0.00020740251485476345
iter 7750 , loss 0.05414936 , lr 0.00020191755856162393
iter 8000 , loss 0.04402468 , lr 0.0001963525491562421
iter 8250 , loss 0.053489193 , lr 0.00019071606747976113
iter 8500 , loss 0.05694989 , lr 0.0001850168045783858
iter 8750 , loss 0.055731468 , lr 0.00017926354830241924
iter 9000 , loss 0.04592497 , lr 0.00017346516975603462
iter 9250 , loss 0.060285483 , lr 0.00016763060961867566
iter 9500 , loss 0.064131975 , lr 0.00016176886435917675
iter 9750 , loss 0.0601519 , lr 0.0001558889723638603
iter 10000 , loss 0.06482653 , lr 0.00015
iter 10250 , loss 0.04579177 , lr 0.0001441110276361397
iter 10500 , loss 0.046591006 , lr 0.00013823113564082325
iter 10750 , loss 0.054461196 , lr 0.0001323693903813244
iter 11000 , loss 0.041555915 , lr 0.0001265348302439654
iter 11250 , loss 0.0542693 , lr 0.00012073645169758072
iter 11500 , loss 0.044762943 , lr 0.0001149831954216142
iter 11750 , loss 0.038731456 , lr 0.00010928393252023886
iter 12000 , loss 0.044237886 , lr 0.0001036474508437579
iter 12250 , loss 0.036766857 , lr 9.808244143837605e-05
iter 12500 , loss 0.047858626 , lr 9.259748514523656e-05
iter 12750 , loss 0.049839787 , lr 8.720103936938576e-05
iter 13000 , loss 0.044046156 , lr 8.190142503906798e-05
iter 13250 , loss 0.044242196 , lr 7.670681377545674e-05
iter 13500 , loss 0.038682327 , lr 7.162521529260767e-05
iter 13750 , loss 0.047561176 , lr 6.66644650470597e-05
iter 14000 , loss 0.039865553 , lr 6.183221215612904e-05
iter 14250 , loss 0.039226405 , lr 5.7135907603524936e-05
iter 14500 , loss 0.04380694 , lr 5.2582792750472464e-05
iter 14750 , loss 0.042341575 , lr 4.817988817005873e-05
iter 15000 , loss 0.044054512 , lr 4.3933982822017876e-05
iter 15250 , loss 0.04150852 , lr 3.9851623584647144e-05
iter 15500 , loss 0.038706996 , lr 3.593910515999536e-05
iter 15750 , loss 0.03962469 , lr 3.220246036788829e-05
iter 16000 , loss 0.040832553 , lr 2.8647450843757897e-05
iter 16250 , loss 0.038274407 , lr 2.5279558154618197e-05
iter 16500 , loss 0.034568787 , lr 2.210397534688617e-05
iter 16750 , loss 0.04634787 , lr 1.912559893908042e-05
iter 17000 , loss 0.050864935 , lr 1.634902137174483e-05
iter 17250 , loss 0.043062124 , lr 1.3778523926237827e-05
iter 17500 , loss 0.036971226 , lr 1.1418070123306989e-05
iter 17750 , loss 0.03856273 , lr 9.271299611627391e-06
iter 18000 , loss 0.042704187 , lr 7.34152255572697e-06
iter 18250 , loss 0.042256206 , lr 5.631714531952908e-06
iter 18500 , loss 0.04105115 , lr 4.144511940348516e-06
iter 18750 , loss 0.040660076 , lr 2.882207939515435e-06
iter 19000 , loss 0.039436445 , lr 1.8467489107293509e-06
iter 19250 , loss 0.039670467 , lr 1.0397314567610559e-06
iter 19500 , loss 0.03676471 , lr 4.623999400308054e-07
iter 19750 , loss 0.041069247 , lr 1.1564456389156485e-07
iter 20000 , loss 0.050390124 , lr 0.0
                                  
================================= 
Global information about the job: 
================================= 
  
Job owner: saumi(54773)
Job name:  isa-scclevr-EncStudy-moreCNN
Node list: ravg1022
Job start: Sat Jan  6 09:02:56 CET 2024
Job end:   Sat Jan  6 10:29:43 CET 2024
Work dir:  /raven/u/saumi/multi-object-detection/Slot-Attention/code
Command:   /raven/u/saumi/multi-object-detection/Slot-Attention/code/slurm_scripts/isa-scclevr-EncStudy-moreCNN.sh
  
  
  
==========================================================================================
Information on jobsteps (Note: MaxRSS/AveRSS is the maximum/average over all 
tasks of the per-task memory high-water marks; cf. "man sacct"): 
==========================================================================================
  
JobID            JobName NNodes NTasks  NCPUS       MaxRSS       AveRSS    Elapsed ExitCode
------------- ---------- ------ ------ ------ ------------ ------------ ---------- --------
8900295       isa-scclev      1             8                             01:26:47      0:0
  
Maximum memory per node: 3.291091 GB (defined as MaxRSS*Ntasks/NNodes)
CPU utilization: 24.8 %
  
