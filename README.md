# README

**Goal:** Let's start getting a basic slot attention example together on a toy problem.

## Step 1: Get code

### 1a) Clone this repo

### 1b) Parallel to this repo, clone my fork of the `google-research` repo

`git clone https://github.com/nhartman94/google-research.git`

I've editted the `slot_attention/model.py` to add a new class `SlotAttentionSara` to have the dimesnionalty that is what I remember as the dimension for your problem!

### Step 2: Train model

This code lives in `Toy-prob.ipynb`.

I made a toy 2 photon case that hopefully will be easy to plug and play with your dataset!


June 2023